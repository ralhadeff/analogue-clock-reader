{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data files list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'data/'\n",
    "# get all file names\n",
    "files = [f for f in listdir(folder) if f[-4:]=='.png']\n",
    "# load one to get the dimensions\n",
    "image = mpimg.imread(f'{folder}{files[0]}')\n",
    "# get dimensions\n",
    "shape = list(image.shape)\n",
    "# remove alpha if necessary\n",
    "if (shape[2]==4):\n",
    "    shape[2] = 3\n",
    "n = len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.zeros(shape=n,dtype=int)\n",
    "X = np.zeros(shape=(n,*shape))\n",
    "for i in range(len(files)):\n",
    "    # get the hour from the file name\n",
    "    y[i] = re.search('^([0-9]*)_',files[i])[1]\n",
    "    # get the pixels, remove the alpha if needed and convert to 0-255\n",
    "    X[i] = (mpimg.imread(f'{folder}{files[i]}')[:,:,:shape[2]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data to training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note, the input files are already shuffled\n",
    "train = 0.8\n",
    "cutoff = int(len(X) * train)\n",
    "\n",
    "\n",
    "# reorder channel for torch\n",
    "X_train = np.moveaxis(X[:cutoff],3,1)\n",
    "y_train = y[:cutoff]\n",
    "\n",
    "X_test = np.moveaxis(X[cutoff:],3,1)\n",
    "y_test = y[cutoff:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAEyCAYAAACbGke8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKoQagKgQagCi8r+2hj5NNBOHfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(0,n)\n",
    "print(i)\n",
    "print(y[i])\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(X[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        # get number of neurons after flatten\n",
    "        self.flat = self.get_flat(X_train[0].shape)\n",
    "        self.fc1=torch.nn.Linear(self.flat,256)\n",
    "        self.dropout=torch.nn.Dropout(p=0.5)\n",
    "        self.output=torch.nn.Linear(256,12)\n",
    "            \n",
    "    def forward(self,X):\n",
    "        relu = torch.nn.functional.relu\n",
    "        x = relu(self.conv1(X))\n",
    "        x = relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, self.flat)\n",
    "        x = relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        x = torch.nn.functional.softmax(x,dim=1)\n",
    "        x = torch.argmax(x,dim=1).float()\n",
    "        return x\n",
    "    \n",
    "    def get_flat(self, input_shape):\n",
    "        x = torch.autograd.Variable(torch.rand(1, *input_shape))\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        return x.data.view(1, -1).size(1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of scalar type Long but got scalar type Float for argument #2 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-c60a6176056d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# calculate loss and do backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 904\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1788\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of scalar type Long but got scalar type Float for argument #2 'target'"
     ]
    }
   ],
   "source": [
    "# work in progress\n",
    "model = Model()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20\n",
    "batches = 50\n",
    "batch_size = len(X_train)//batches\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for b in range(batches):\n",
    "        # get batch\n",
    "        batch = X_train[b*batch_size:(b+1)*batch_size]\n",
    "        batch = torch.autograd.Variable(torch.Tensor(batch))\n",
    "        y_b = torch.autograd.Variable(torch.Tensor(y_train[b*batch_size:(b+1)*batch_size]).float()).view(1, -1)\n",
    "        # prepare optimizer\n",
    "        optimizer.zero_grad()\n",
    "        # get output\n",
    "        outputs = model(batch).view(1, -1)\n",
    "        # calculate loss and do backprop\n",
    "        l = loss(outputs,y_b)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch:' + str(epoch+1) + ', loss:' + str(float(loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  3,  7,  7,  7,  7,  7,  7, 10,  3,  7,  3,  7,  3,  7,  7, 10,\n",
       "        3,  7,  7,  3,  7,  7, 10, 10,  7,  7,  7,  3,  7,  3,  7,  7,  7,\n",
       "        7, 10,  7,  3,  7,  7,  7,  3,  7,  3,  7,  7,  7,  7,  3,  7,  3,\n",
       "        7,  7,  7,  3,  7,  7,  7,  3,  7,  7,  7,  3,  7,  7,  7,  7, 10,\n",
       "       10,  3,  7,  3,  7,  3,  7,  7,  3,  7,  3,  7,  7,  7,  3,  7,  7,\n",
       "        7,  7,  6,  7,  7,  3,  7, 10,  7,  7,  3,  7,  7, 10,  3,  3, 10,\n",
       "        6,  3, 11, 10,  7,  3,  3, 11,  7,  3,  7,  3,  7, 10,  3,  3,  7,\n",
       "        7,  7,  7,  7, 10,  3,  7, 10,  3,  7,  7,  7, 10,  7,  7,  7,  3,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  3,  3, 10,  7,  3,  7,  3,  3,\n",
       "        7,  3,  7,  7, 10,  7,  4,  7,  7,  3,  2,  7,  7,  7,  3, 10, 10,\n",
       "        7,  3,  7,  7,  3,  7, 10,  3,  7,  3,  3, 10,  7,  3, 11,  7,  3,\n",
       "        3,  7,  3,  3,  7,  7,  7,  7,  3,  7,  7,  7,  3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(torch.autograd.Variable(torch.Tensor(X_test))).detach().numpy()\n",
    "#pred = np.argmax(pred,axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 10, 10,  9, 11,  8,  3,  3,  4,  2,  8, 11,  4,  5,  9,  8, 12,\n",
       "       12, 12,  9,  1,  5, 12,  3,  6,  1,  1, 10,  1, 12,  6,  1,  2, 10,\n",
       "       11,  2, 12,  4,  5,  4,  5,  3, 11,  9, 11,  6,  2, 11,  8,  4,  2,\n",
       "        5,  9,  1,  4, 12,  5,  5,  7,  2, 10, 10, 11, 10,  5, 11,  2,  7,\n",
       "       12,  7,  2, 12,  9,  8,  1,  8,  8,  9,  3,  2,  9, 11,  3,  8,  4,\n",
       "       10,  2,  3, 11,  8,  6,  9,  1,  3, 11, 10,  3,  8, 11,  9, 12,  4,\n",
       "        7, 11,  9,  2,  5,  1,  5,  9,  6,  9,  4,  3, 12,  8,  7,  8, 11,\n",
       "       11,  4,  9, 11,  8,  4,  6, 11,  5,  5,  5,  7,  3,  1,  2,  8,  3,\n",
       "        6,  7, 12,  1,  4,  4, 11, 10,  6, 10, 11, 10,  7,  8,  1,  6,  2,\n",
       "        9,  7,  9, 10,  4,  2,  6,  8, 10,  5,  6, 10,  2,  3,  7, 10,  1,\n",
       "        2,  3, 11,  7,  7,  5, 10,  2,  5, 12, 11,  6,  2, 12, 10, 12,  8,\n",
       "        4,  4,  4,  6, 11,  6,  5,  1,  1,  7,  9, 10, 12])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(torch.autograd.Variable(torch.Tensor(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 5, 9, 9, 9, 9, 5, 9, 9, 9, 1, 7, 9, 9, 9, 9, 0, 7, 9, 7, 9, 9, 7, 9,\n",
       "        5, 9, 9, 9, 9, 5, 9, 1, 9, 7, 9, 9, 1, 9, 5, 5, 5, 9, 7, 9, 9, 9, 9, 9,\n",
       "        9, 9, 5, 9, 9, 9, 9, 9, 9, 9, 5, 9, 5, 5, 9, 3, 7, 5, 1, 9, 9, 7, 9, 9,\n",
       "        3, 9, 9, 5, 9, 5, 7, 9, 9, 9, 9, 9, 5, 9, 9, 9, 9, 9, 9, 9, 1, 9, 9, 9,\n",
       "        9, 7, 1, 9, 9, 9, 5, 9, 9, 9, 9, 9, 9, 9, 9, 7, 9, 0, 9, 7, 9, 9, 7, 9,\n",
       "        9, 9, 5, 5, 9, 7, 5, 9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 9, 5, 9, 9, 9, 9, 5,\n",
       "        9, 7, 9, 9, 5, 5, 9, 9, 9, 9, 9, 9, 9, 9, 5, 5, 9, 9, 7, 7, 9, 1, 9, 5,\n",
       "        9, 5, 5, 9, 9, 9, 9, 1, 9, 9, 5, 9, 9, 7, 3, 9, 9, 9, 9, 1, 5, 9, 5, 9,\n",
       "        9, 5, 5, 5, 9, 9, 5, 5])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(pred,dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
